{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from itertools import permutations\n",
    "import sys\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Activation, concatenate, Conv1D, Dropout, Input, Lambda\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Allows me to import my modules\n",
    "sys.path.append('./modules')\n",
    "from audio_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kltls = ['bass_drum-normal','hi_hat-normal',\n",
    "  'hi_hat-open',\n",
    "  'high_tom-normal',\n",
    "  'ride-normal',\n",
    "  'ride-bell',\n",
    "  'crash-normal',\n",
    "  'snare-normal',\n",
    "  'low_tom-normal',\n",
    "  'mid_tom-normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_ys(labels):\n",
    "    ys = np.zeros(len(kltls))\n",
    "    for n in range(len(kltls)):\n",
    "        kl, tl = kltls[n].split(\"-\")\n",
    "        for label_i in range(len(labels[\"hit_label\"])):\n",
    "            if (kl in labels[\"kit_label\"][label_i] and tl in labels[\"tech_label\"][label_i]):\n",
    "                ys[n] = 1\n",
    "    return ys\n",
    "\n",
    "def ys_to_labels(ys, threshold = 0.6):\n",
    "    labels = {\"hit_label\": [], \"kit_label\": [], \"tech_label\": []}\n",
    "    for n in range(len(kltls)):\n",
    "        kl, tl = kltls[n].split(\"-\")\n",
    "        if (ys[n] > threshold):\n",
    "            hl = \"beater\" if kl == \"bass_drum\" else \"stick\"\n",
    "            labels[\"hit_label\"].append(hl)\n",
    "            labels[\"kit_label\"].append(kl)\n",
    "            labels[\"tech_label\"].append(tl)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioGenerator(Sequence):\n",
    "    def get_ys(self, labels):\n",
    "        return labels_to_ys(labels)\n",
    "    \n",
    "    def __init__(self, filenames, labels, data_type):\n",
    "        self.filenames, self.labels, self.batch_size = filenames, labels, SETTINGS.data[data_type][\"batch_size\"]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([np.loadtxt(file_name) for file_name in batch_x]), np.array(list(map(self.get_ys, batch_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "generators = {\"training\": None, \"test\": None}\n",
    "for data_type in generators.keys():\n",
    "    sample_metadata = get_file_classes(data_type)\n",
    "    filenames = [sm[\"filepath\"] for sm in sample_metadata]\n",
    "    labels = [sm[\"labels\"] for sm in sample_metadata]\n",
    "    generators[data_type] = AudioGenerator(filenames, labels, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picklable: True\n"
     ]
    }
   ],
   "source": [
    "# Test whether generator arguments are picklable (whether they can be multiprocessed)\n",
    "use_multiprocessing = True\n",
    "for gen in generators:\n",
    "    try:\n",
    "        pickle.dumps(gen)\n",
    "    except:\n",
    "        print(sys.exc_info())\n",
    "        use_multiprocessing = False\n",
    "        break\n",
    "print(\"Picklable:\", use_multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://keras.io/layers/writing-your-own-keras-layers/\n",
    "def InceptionModule(model):\n",
    "    # Skip connection (uses input in concat)\n",
    "    skip = Lambda(lambda x: x)(model)\n",
    "    # Size 1 kernel conv of input (with tanh activation)\n",
    "    conv_1_tower = Conv1D(filters=32, kernel_size=1, strides=1, padding=\"valid\", activation=\"tanh\")(model)\n",
    "    # Size 1 -> size 3 kernel conv of input (with tanh activation)\n",
    "    conv_3_tower = Conv1D(filters=1, kernel_size=1, strides=1, padding=\"valid\")(model)\n",
    "    conv_3_tower = Conv1D(filters=32, kernel_size=3, strides=1, padding=\"causal\", activation=\"tanh\")(conv_3_tower)\n",
    "    # Size 1 -> size 5 kernel conv of input (with tanh activation)\n",
    "    conv_5_tower = Conv1D(filters=1, kernel_size=1, strides=1, padding=\"valid\")(model)\n",
    "    conv_5_tower = Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"tanh\")(conv_5_tower)\n",
    "    # Size 1 -> size 7 kernel conv of input (with tanh activation)\n",
    "    conv_7_tower = Conv1D(filters=1, kernel_size=1, strides=1, padding=\"valid\")(model)\n",
    "    conv_7_tower = Conv1D(filters=32, kernel_size=7, strides=1, padding=\"causal\", activation=\"tanh\")(conv_7_tower)\n",
    "    # Concatenate all activation images\n",
    "    return concatenate([skip, conv_1_tower, conv_3_tower, conv_5_tower, conv_7_tower], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable dilated convolution / inception module / dropout layer\n",
    "def DilatedInceptionModuleLayer(model, drop_rate):\n",
    "    model = Conv1D(filters=32, kernel_size=1, padding=\"causal\", dilation_rate=2)(model)\n",
    "    model = InceptionModule(model)\n",
    "    return Dropout(rate=drop_rate)(model)\n",
    "\n",
    "dim_rates = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "# Structure\n",
    "\"\"\"\n",
    "Rationale: \n",
    "\n",
    "3 \"CausalConvAct\" convolution layers which reduce the size of the sample space while increasing the size of the convolution space.\n",
    "- Providing downscaling\n",
    "(Feature extraction, while preserving temporal relationships)\n",
    "\n",
    "Then \"DilatedInceptionModule\" layers which retain the size of the sample space while extracting more features.\n",
    "\n",
    "- Using Convolutions to downsample from LeNet (?)\n",
    "- Dropout paper\n",
    "- ResNet for skip connections\n",
    "- Inception module adapted from GoogLeNet\n",
    "- Causal convolutions from WaveNet\n",
    "\"\"\"\n",
    "data = Input(batch_shape=(100, 12000, 1))\n",
    "cnn = Conv1D(filters=32, kernel_size=7, strides=3, padding=\"causal\", dilation_rate=1, activation=\"tanh\")(data)\n",
    "cnn = Conv1D(filters=32, kernel_size=7, strides=2, padding=\"causal\", dilation_rate=1, activation=\"tanh\")(cnn)\n",
    "cnn = Conv1D(filters=32, kernel_size=5, strides=2, padding=\"causal\", dilation_rate=1, activation=\"tanh\")(cnn)\n",
    "cnn = Dropout(rate=0.1)(cnn)\n",
    "for drop_rate in dim_rates:\n",
    "    DilatedInceptionModuleLayer(cnn, drop_rate)\n",
    "cnn = Activation(\"sigmoid\")(cnn)\n",
    "\n",
    "model = Model(inputs=data, outputs=cnn)\n",
    "# Compile with stocastic gradient descent and mean squared error loss (same as multilabelled paper)\n",
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit_generator(generator=generators[\"training\"],\n",
    "                   validation_data=generators[\"validation\"],\n",
    "                   use_multiprocessing=use_multiprocessing,\n",
    "                   workers=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
