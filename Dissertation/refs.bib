% References
@report{McCullock_Pitts,
author = {{W. S. McCulloch}, W. Pitts},
booktitle = {Bulletin of mathematical biology},
number = {1-2},
pages = {99--115.},
publisher = {Bulletin of Mathematical Biophysics},
title = {{A logical calculus of the ideas immanent in nervous activity}},
volume = {52},
year = {1990}
}
@report{Yann_LeCun_et_al,
author = {Y, LeCun and L, Bottou and Y, Bengio and P, Haffner},
booktitle = {Proceedings of the IEEE},
pages = {2278--2324},
publisher = {IEEE},
title = {{Gradient-Based Learning Applied to Document Recognition}},
year = {1998}
}
@online{Nielsen,
abstract = {applicability for this approach.},
annote = {[Online; accessed on 22-10-2018]},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Theodoridis, Sergios},
booktitle = {Machine Learning},
doi = {10.1016/B978-0-12-801522-3.00018-5},
eprint = {arXiv:1011.1669v3},
isbn = {978-3-319-94462-3},
issn = {1098-6596},
pages = {875--936},
pmid = {25246403},
title = {{Neural Networks and Deep Learning}},
url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128015223000185},
year = {2015}
}
@book{Cawsey,
abstract = {A concise, practical introduction to artificial intelligence, this title starts with the fundamentals of knowledge representation, inference, expert systems, natural language processing, machine learning, neural networks, agents, robots, and much more. Examples and algorithms are presented throughout, and the book includes a complete glossary},
author = {Cawsey, Alison},
booktitle = {Essence of computing series},
doi = {10.1037/h0072647},
isbn = {0135717795 (pbk. alk. paper)},
issn = {0033295X},
keywords = {Artificial intelligence.,Expert systems (Computer science)},
pages = {ix, 190 p.},
pmid = {4015403},
publisher = {Prentice Hall Europe},
title = {{The essence of artificial intelligence}},
url = {http://www.loc.gov/catdir/toc/fy034/97011460.html},
year = {1998}
}
@book{Rojas,
author = {Rojas, Raul},
doi = {10.1109/78.127967},
isbn = {9783540605058},
issn = {1053587X},
pages = {152 -- 184},
publisher = {Springer-Verlag},
title = {{Neural Networks - A Systematic Introduction - Backpropagation}},
url = {https://page.mi.fu-berlin.de/rojas/neural/neuron.pdf},
year = {1996}
}
@book{Muller,
abstract = {This textbook provides both profound technological knowledge and a comprehensive treatment of essential topics in music processing and music information retrieval. Including numerous examples, figures, and exercises, this book is suited for students, lecturers, and researchers working in audio engineering, computer science, multimedia, and musicology.},
author = {M{\"{u}}ller, Meinard},
doi = {10.1007/978-3-319-21945-5},
isbn = {978-3-319-21944-8},
issn = {1029-8649},
pmid = {12525892},
publisher = {Springer-Verlag},
title = {{Fundamentals of Music Processing}},
url = {http://link.springer.com/10.1007/978-3-319-21945-5},
year = {2015}
}
@report{gmsw2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1609.08764v1},
author = {Wong, Sebastien C and Mcdonnell, Mark D},
eprint = {arXiv:1609.08764v1},
institution = {IEEE},
isbn = {9781509028962},
title = {{Understanding data augmentation for classification : when to warp ?}},
year = {2016}
}
@report{ghlmowyzz2017,
abstract = {Dental intrusion and avulsion, crown fracture and mandibular fractures are important dentofacial complications in patients with epilepsy-related traumas. The objective of the present study was to describe the occurrence of orofacial injuries in patients with epilepsy. One hundred and nine consecutive patients (60 women; mean age 38.81 +/- 14 years), treated for refractory epilepsy (45 with extratemporal epilepsy and 64 with temporal epilepsy) at the outpatient clinic of our University Hospital, were included in the present study. Orofacial injury occurring as a direct result of a seizure was determined by clinical examination and interview. In addition, seizure frequency, use of medication, and the occurrence and type of injury to other parts of the body, were documented. We employed regression analyses to investigate the association between teeth fractures and frequency of seizures. The majority of injuries were crown fractures (42 subjects), followed by mandibular fractures (eight subjects) and tooth avulsion (eight subjects). Sixteen patients had more than two fractured teeth. Patients with mandibular trauma also suffered concomitant injuries (teeth fracture, avulsion and dislocation). The number of fractured teeth was associated with seizure frequency (r(2) = 0.59, p {\textless} 0.001). The data suggest that there is an increased rate of dentoalveolar and maxillofacial injuries in patients with poorly controlled epileptic seizures.},
author = {Maxwell, Andrew and Li, Runzhi and Yang, Bei and Weng, Heng and Ou, Aihua and Hong, Huixiao and Zhou, Zhaoxian and Gong, Ping and Zhang, Chaoyang},
booktitle = {BMC Bioinformatics},
doi = {10.1186/s12859-017-1898-z},
institution = {BMC Bioinformatics},
issn = {14712105},
keywords = {Deep learning,Deep neural networks,Intelligent health risk prediction,Medical health records,Multi-label classification},
pmid = {21393092},
title = {{Deep learning architectures for multi-label classification of intelligent health risk prediction}},
volume = {18},
year = {2017}
}
@online{MNIST,
abstract = {Current analytical models of grasping and manipulation with robotic hands contain simplifications and assumptions that limit their application to manufacturing environments. To evaluate these models, a study was undertaken of the grasps used by machinists in a small batch manufacturing operation. Based on the study, a taxonomy of grasps was constructed. An expert system was also developed to clarify the issues involved in human grasp choice. Comparisons of the grasp taxonomy, the expert system, and grasp-quality measures derived from the analytic models reveal that the analytic measures are useful for describing grasps in manufacturing tasks despite the limitations in the models. In addition, the grasp taxonomy provides insights for the design of versatile robotic hands for manufacturing},
annote = {[Online; accessed on 22-10-2018]},
author = {Lecun, Yann},
booktitle = {html(MNIST dataset)},
doi = {10.1109/70.34763},
issn = {1042-296X},
pages = {1--8},
pmid = {1000253529},
title = {{THE MNIST DATABASE of handwritten digits}},
url = {http://yann.lecun.com/exdb/mnist/},
year = {2010}
}
@article{AE2006,
abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {AE, van den Bosch and D, Ten Harkel and JS, McGhie and JW, Roos-Hesselink and ML, Simoons and AJJ, Bogers and FJ, Meijboom},
doi = {10.1109/5.726791},
eprint = {1102.0183},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/CNN paper.pdf:pdf},
journal = {Journal of the American Society of Echocardiography},
keywords = {Child, Preschool,Clinical Trials,Computer Systems,Descriptive Statistics,Echocardiography, Three-Dimensional -- Methods,Female,Heart Septal Defects, Atrial -- Ultrasonography,Human,Image Enhancement -- Methods,Image Interpretation, Computer Assisted -- Methods,Linear Regression,Male,Middle Age,P-Value,Paired T-Tests,Reproducibility of Results,Sensitivity and Specificity},
number = {6},
pages = {815--821},
pmid = {15823584},
title = {{Characterization of atrial septal defect assessed by real-time 3-dimensional echocardiography.}},
url = {http://ezproxy.bangor.ac.uk/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=c8h{\&}AN=106117907{\&}site=ehost-live},
volume = {19},
year = {2006}
}
@article{Bello2005,
abstract = {Note onset detection and localization is useful in a number of analysis and indexing techniques for musical signals. The usual way to detect onsets is to look for “transient” regions in the signal, a notion that leads to many definitions: a sudden burst of energy, a change in the short-time spectrum of the signal or in the statistical properties, etc. The goal of this paper is to review, categorize, and compare some of the most commonly used techniques for onset detection, and to present possible enhancements. We discuss methods based on the use of explicitly predefined signal features: the signal's amplitude envelope, spectral magnitudes and phases, time-frequency representations; and methods based on probabilistic signal models: model-based change point detection, surprise signals, etc. Using a choice of test cases, we provide some guidelines for choosing the appropriate method for a given application.},
author = {Bello, Juan Pablo and Daudet, Laurent and Abdallah, Samer and Duxbury, Chris and Davies, Mike and Sandler, Mark B.},
doi = {10.1109/TSA.2005.851998},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/onset{\_}detection.pdf:pdf},
journal = {IEEE Transactions on Speech and Audio Processing},
keywords = {Attack transcients,Audio,Note segmentation,Novelty detection},
number = {5},
pages = {1035--1046},
pmid = {1000106150},
title = {{A tutorial on onset detection in music signals}},
volume = {13},
year = {2005}
}
@online{Raschka,
annote = {[Online; accessed on 17-10-2018]},
author = {Raschka, Sebastian},
title = {{Single-Layer Neural Networks and Gradient Descent}},
url = {https://sebastianraschka.com/Articles/2015{\_}singlelayer{\_}neurons.html}
}
@techreport{Paulus2010,
abstract = {This thesis proposes signal processing methods for the analysis of musical audio on two time scales: drum transcription on a finer time scale and music structure analysis on the time scale of entire pieces. The former refers to the process of locating drum sounds in the input and recognising the instruments that were used to produce the sounds. The latter refers to the temporal segmentation of a musical piece into parts, such as chorus and verse. For drum transcription, both low-level acoustic recognition and high-level musicological modelling methods are presented. A baseline acoustic recognition method with a large number of features using Gaussian mixture models for the recognition of drum combinations is presented. Since drums occur in structured patterns, modelling of the sequential dependencies with N-grams is proposed. In addition to the conventional N-grams, periodic N-grams are proposed to model the dependencies between events that occur one pattern length apart. The evaluations show that incorporating musicological modelling improves the performance considerably. As some drums are more probable to occur at certain points in a pattern, this dependency is utilised for producing transcriptions of signals produced with arbitrary sounds, such as beatboxing. A supervised source separation method using non-negative matrix factorisation is proposed for transcribing mixtures of drum sounds. Despite the simple signal model, a high performance is obtained for signals without other instruments. Most of the drum transcription methods operate only on single-channel inputs, but multichannel signals are available in recording studios. A multichannel extension of the source separation method is proposed, and an increase in performance is observed in evaluations. Many of the drum transcription methods rely on detecting sound onsets for the segmentation of the signal. Detection errors will then decrease the overall performance of the system. To overcome this problem, a method utilising a network of connected hidden Markov models is proposed to perform the event segmentation and recognition jointly. The system is shown to be able to perform the transcription even from polyphonic music. The second main topic of this thesis is music structure analysis. Two methods are proposed for this purpose. The first relies on defining a cost function for a description of the repeated parts. The second method defines a fitness function for descriptions covering the entire piece. The abstract cost (and fitness) functions are formulated in terms that can be determined from the input signal algorithmically, and optimisation problems are formulated. In both cases, an algorithm is proposed for solving the optimisation problems. The first method is evaluated on a small data set, and the relevance of the cost function terms is shown. The latter method is evaluated on three large data sets with a total of 831 (557+174+100) songs. This is to date the largest evaluation of a structure analysis method. The evaluations show that the proposed method outperforms a reference system on two of the data sets. Music structure analysis methods rarely provide musically meaningful names for the parts in the result. A method is proposed to label the parts in descriptions based on a statistical model of the sequential dependencies between musical parts. The method is shown to label the main parts relatively reliably without any additional information. The labelling model is further integrated into the fitness function based structure analysis method.},
author = {Paulus, Jouni},
booktitle = {{\ldots}teknillinen yliopisto. Julkaisu-Tampere University of {\ldots}},
doi = {DOI: 10.1007/s11214-007-9186-2},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/paulus{\_}phd.pdf:pdf},
isbn = {9789521523052},
title = {{Signal processing methods for drum transcription and music structure analysis}},
url = {http://dspace.cc.tut.fi/dpub/handle/123456789/6445},
year = {2010}
}
@techreport{Paulus2005,
abstract = {This paper describes a novel method for the automatic transcrip- tion of drum sequences. The method is based on separating the target drum sounds from the input signal using non-negative ma- trix factorisation, and on detecting sound onsets from the separated signals. The separation algorithm factorises the spectrogram of the input signal into a sum of instrument spectrograms, each having a fixed spectrum and a time-varying gain. The spectra are cal- culated from a set of training signals, and the time-varying gains are estimated with an algorithm stemming from non-negative ma- trix factorisation. Onset times of the instruments are detected from the estimated time-varying gains. The system gave better results than two state-of-the-art methods in simulations with acoustic sig- nals containing polyphonic drum sequences, and overall hit rate of 96{\%} was accomplished. Demonstrational signals are available at http://www.cs.tut.fi/˜paulus/demo/.},
author = {Paulus, J and Virtanen, T},
booktitle = {Proc. of 13th European Signal Processing Conference (EUSIPCO2005)},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/eusipco05{\_}paulus.pdf:pdf},
isbn = {978-160-4238-21-1},
title = {{Drum transcription with non-negative spectrogram factorisation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.3075{\&}rep=rep1{\&}type=pdf{\%}5Cnpapers3://publication/uuid/DE679231-A624-4B10-8A44-F79FC5611AC9},
year = {2005}
}
@book{Russell;Norvig1995,
abstract = {The long-anticipated revision of this best-selling book offers the most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For those interested in artificial intelligence.},
author = {{Russell; Norvig}},
booktitle = {Neurocomputing},
doi = {10.1016/0925-2312(95)90020-9},
isbn = {9780131038059},
issn = {09252312},
number = {2},
pages = {215--218},
pmid = {20949757},
title = {{Artificial Intelligence: A Modern Approach}},
url = {http://portal.acm.org/citation.cfm?id=773294},
volume = {9},
year = {1995}
}
@techreport{Nair2010,
abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an inﬁnite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these “Stepped Sigmoid Units” are unchanged. They can be approximated eﬃciently by noisy, rectiﬁed linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face veriﬁcation on the Labeled Faces in the Wild dataset. Unlike binary units, rectiﬁed linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Nair, V and international Conference, GE Hinton - Proceedings of the 27th and 2010, Undefined},
booktitle = {Cs.Toronto.Edu},
doi = {10.1.1.165.6419},
eprint = {1111.6189v1},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/reluICML.pdf:pdf},
institution = {University of Toronto},
isbn = {9781605589077},
issn = {1935-8237},
mendeley-groups = {Dissertation Refs},
pages = {6421113},
pmid = {22404682},
title = {{Rectified Linear Units Improve Restricted Boltzmann Machines}},
url = {https://www.cs.toronto.edu/{~}hinton/absps/reluICML.pdf},
year = {2010}
}
@techreport{Hinton2014,
author = {Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/JMLRdropout.pdf:pdf},
institution = {University of Toronto},
mendeley-groups = {Dissertation Refs},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
url = {https://www.cs.toronto.edu/{~}hinton/absps/JMLRdropout.pdf},
year = {2014}
}
@techreport{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Hinton, Geoffrey E and Sutskever, Ilya},
booktitle = {Neural Information Processing Systems},
doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
eprint = {1102.0183},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf:pdf},
institution = {Univeristy of Toronto},
isbn = {9781627480031},
issn = {10495258},
mendeley-groups = {Dissertation Refs},
pages = {1--9},
pmid = {7491034},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
year = {2012}
}
@techreport{Hubel1959,
abstract = {Recordings were made in lightly anaesthesized cats whose retinas were stimulated, singly or together, with light spots of various sizes and shapes. Receptive fields, defined as restricted areas where illumination influenced the firing of a single cortical unit, usually contained mutually antagonistic excitatory and inhibitory regions. Thus a stimulus covering a whole field was relatively ineffective in driving most units. Effective driving of a unit required a stimulus specific in form, size, position, and orientation; based on the arrangement of excitatory and inhibitory areas. About 20{\%} of the cortical units studied could be activated from either eye; these were driven from roughly homologous regions of the retinas and summation and antagonism could be shown. (PsycINFO Database Record (c) 2009 APA, all rights reserved)},
author = {Hubel, D. H. and Wiesel, T. N.},
booktitle = {The Journal of Physiology},
doi = {10.1113/jphysiol.1959.sp006308},
file = {:D$\backslash$:/Documents/University/Year3/Independant Studies/Dissertation/Hubel{\_}et{\_}al-1959-The{\_}Journal{\_}of{\_}Physiology.pdf:pdf},
isbn = {0022-3751 (Print)},
issn = {14697793},
mendeley-groups = {Dissertation Refs},
number = {3},
pages = {574--591},
pmid = {14403679},
title = {{Receptive fields of single neurones in the cat's striate cortex}},
url = {http://doi.wiley.com/10.1113/jphysiol.1959.sp006308},
volume = {148},
year = {1959}
}


%Figures
@misc{drumschematic,
    author = {Syed Wamiq Ahmed Hashmi},
    title = {Drums schematic},
    year = {2013},
    note = {[Online, used in accordance with the Wikipedia Commons, creative commons license; accessed on 21-01-2019]},
    url = {https://upload.wikimedia.org/wikipedia/commons/5/57/Drums_schematic.svg},
    keyword={figure}
}

@misc{convolutionpooling,
    author = {ID 12019},
    title = {Kingfisher},
    year = {2017},
    note = {[Online, adapted in accordance with the Pixabay License; accessed on 23-01-2019]},
    url = {https://pixabay.com/en/kingfisher-bird-wildlife-macro-2046453/},
    keyword={figure}
}