{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read settings file...\n",
      "\tRead successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Add, Conv1D, Dense, Dropout, Flatten, Input, LeakyReLU\n",
    "from keras.losses import binary_crossentropy, kullback_leibler_divergence\n",
    "from keras.metrics import categorical_accuracy\n",
    "from custom_metric import rounded_all_or_nothing_acc as RAON_accuracy\n",
    "from keras.models import Model\n",
    "from generator import AudioGenerator, kltls, multilabelled_labels_to_ys, multilabelled_ys_to_labels, onehot_superclass_labels_to_ys, onehot_superclass_ys_to_labels, MULTI_LABEL, ONE_HOT, TIME_SEQUENCE, LINEAR_SPECTROGRAM, LOG_SPECTROGRAM\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "from keras.callbacks import TensorBoard\n",
    "from time_callback import Time_Callback\n",
    "\n",
    "# Allows me to import my modules\n",
    "sys.path.append('./modules')\n",
    "from audio_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12779511779614839501, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 577778483\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 14107562855080368680\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 650, pci bus id: 0000:01:00.0, compute capability: 3.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tells Tensorflow to use the GPU\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : 1,\n",
    "                                        'GPU' : 1},\n",
    "                        log_device_placement = True,\n",
    "                        gpu_options=gpu_options\n",
    "                       )\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "#Loss flags\n",
    "BINARY_CROSSENTROPY = 0\n",
    "KL_DIVERGENCE = 1\n",
    "LOSSES = {BINARY_CROSSENTROPY: binary_crossentropy, KL_DIVERGENCE: kullback_leibler_divergence}\n",
    "\n",
    "# Model config\n",
    "problem_type = ONE_HOT\n",
    "input_type = TIME_SEQUENCE\n",
    "loss = BINARY_CROSSENTROPY\n",
    "optimizer = \"sgd\"\n",
    "\n",
    "# Name of model save and log\n",
    "problem_type_str = \"OneHot\" if problem_type == ONE_HOT else \"MultiHot\"\n",
    "input_type_str = {TIME_SEQUENCE: \"(1D)\", LINEAR_SPECTROGRAM: \"(linear 2D)\", LOG_SPECTROGRAM: \"(log 2D)\"}[input_type]  \n",
    "loss_str = \"BCE\" if loss == BINARY_CROSSENTROPY else \"KLD\"\n",
    "optimizer_str = optimizer.upper()\n",
    "date_time_str = str(datetime.datetime.now().strftime('%d-%m-%Y_%H-%M-%S'))\n",
    "model_name = \"ModelB-{}-{}-{}-{}_{}\".format(input_type_str, problem_type_str, loss_str, optimizer_str, date_time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "batch_size = 50\n",
    "generators = {\"training\": None, \"validation\": None, \"test\": None}\n",
    "N = {\"training\": 0, \"validation\": 0, \"test\": 0}\n",
    "for data_type in generators.keys():\n",
    "    sample_metadata = get_file_classes(data_type)\n",
    "    N[data_type] = len(sample_metadata)\n",
    "    filenames = [sm[\"filepath\"] for sm in sample_metadata]\n",
    "    labels = [sm[\"labels\"] for sm in sample_metadata]\n",
    "    generators[data_type] = AudioGenerator(filenames, labels, data_type, batch_size, shuffle=True, problem_type=ONE_HOT, input_type=TIME_SEQUENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen training\n",
      "In shape: (50, 12000, 1) \n",
      "Out shape: (50, 87)\n",
      "Gen validation\n",
      "In shape: (50, 12000, 1) \n",
      "Out shape: (50, 87)\n",
      "Gen test\n",
      "In shape: (50, 12000, 1) \n",
      "Out shape: (50, 87)\n"
     ]
    }
   ],
   "source": [
    "batch_x_shape = None\n",
    "batch_y_shape = None \n",
    "for name, gen in generators.items():\n",
    "    print(\"Gen\", name)\n",
    "    batch_0 = gen.__getitem__(0)\n",
    "    print(\"In shape:\", batch_0[0].shape, \"\\nOut shape:\", batch_0[1].shape)\n",
    "    batch_x_shape = batch_0[0].shape\n",
    "    batch_y_shape = batch_0[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picklable: True\n"
     ]
    }
   ],
   "source": [
    "# Test whether generator arguments are picklable (whether they can be multiprocessed)\n",
    "use_multiprocessing = True\n",
    "for gen in generators:\n",
    "    try:\n",
    "        pickle.dumps(gen)\n",
    "    except:\n",
    "        print(sys.exc_info())\n",
    "        use_multiprocessing = False\n",
    "        break\n",
    "print(\"Picklable:\", use_multiprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale\n",
    "\n",
    "### Model structure\n",
    "\n",
    "4 1D casual conv convolution layers which reduce the size of the sample space while increasing the size of the convolution/feature space.\n",
    "\n",
    "Creates feature space of 32, while downscaling the sample space to 500. Compared to 12000, total tensor sizes: 12000 -> 16000 (increase in data).\n",
    "\n",
    "After convoluton layers, LeakyReLU was used for activation because ReLU has been shown to perform well and LeakyReLU takes negatives into account slightly which appear in the data. For this reason He-normal was used to initialise the convolution kernals as this performs well with ReLU.\n",
    "\n",
    "Then 3 lots of \"DilatedDropoutSkipModule\" which retain the size of the sample space while extracting more features. With skip connections preserving earlier features. Finished with dropout layers to aid in generalisation during training.\n",
    "\n",
    "Flattened and passed to a fully-connected (dense layer) which reshapes the network into the output shape.\n",
    "\n",
    "Softmax activation layer for one-hot classification.\n",
    "\n",
    "Techniques from lit review:\n",
    "- LeNet: Convolutions with `stride > 1` to downscale sample space.\n",
    "- Using 1x1 convolution layers to downscale feature space, instead of pooling layers. \n",
    "- Leaky ReLU & He kernal inits.\n",
    "- Dropout for generalisation during training.\n",
    "- ResNet for skip connections.\n",
    "\n",
    "### Loss function\n",
    "\n",
    "Binary cross-entropy was used for this one-hot encoded problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "input_1 (None, 12000, 1)\n",
      "conv1d_1 (None, 4000, 8)\n",
      "conv1d_2 (None, 2000, 16)\n",
      "leaky_re_lu_1 (None, 2000, 16)\n",
      "conv1d_3 (None, 1000, 32)\n",
      "leaky_re_lu_2 (None, 1000, 32)\n",
      "conv1d_4 (None, 500, 32)\n",
      "leaky_re_lu_3 (None, 500, 32)\n",
      "dropout_1 (None, 500, 32)\n",
      "conv1d_5 (None, 500, 1)\n",
      "conv1d_6 (None, 500, 8)\n",
      "conv1d_7 (None, 500, 32)\n",
      "leaky_re_lu_4 (None, 500, 32)\n",
      "add_1 (None, 500, 32)\n",
      "dropout_2 (None, 500, 32)\n",
      "conv1d_8 (None, 500, 1)\n",
      "conv1d_9 (None, 500, 8)\n",
      "conv1d_10 (None, 500, 32)\n",
      "leaky_re_lu_5 (None, 500, 32)\n",
      "add_2 (None, 500, 32)\n",
      "dropout_3 (None, 500, 32)\n",
      "conv1d_11 (None, 500, 1)\n",
      "conv1d_12 (None, 500, 8)\n",
      "conv1d_13 (None, 500, 32)\n",
      "leaky_re_lu_6 (None, 500, 32)\n",
      "add_3 (None, 500, 32)\n",
      "dropout_4 (None, 500, 32)\n",
      "flatten_1 (None, 16000)\n",
      "dense_1 (None, 87)\n"
     ]
    }
   ],
   "source": [
    "# Reusable dilated convolution / inception module / dropout layer\n",
    "def DilatedDropoutSkipModule(og_model, drop_rate):\n",
    "    model = Conv1D(filters=1, kernel_size=1, padding=\"valid\", dilation_rate=1, kernel_initializer='he_normal')(og_model)\n",
    "    model = Conv1D(filters=8, kernel_size=3, padding=\"causal\", dilation_rate=2, kernel_initializer='he_normal')(model)\n",
    "    model = Conv1D(filters=32, kernel_size=3, padding=\"causal\", dilation_rate=2, kernel_initializer='he_normal')(model)\n",
    "    model = LeakyReLU(0.3)(model)\n",
    "    model = Add()([og_model, model])\n",
    "    return Dropout(rate=drop_rate)(model)\n",
    "\n",
    "# The dropout rates and amount of modules.\n",
    "NMODULES = 3\n",
    "DROP_RATES = [0.15, 0.2, 0.25]\n",
    "\n",
    "final_activation = {ONE_HOT: \"softmax\", MULTI_LABEL: 'sigmoid'}[problem_type]\n",
    "\n",
    "# Structure\n",
    "data = Input(shape=(12000, 1))\n",
    "cnn = Conv1D(filters=8, kernel_size=7, strides=3, padding=\"causal\", dilation_rate=1, kernel_initializer='he_normal')(data)\n",
    "cnn = Conv1D(filters=16, kernel_size=7, strides=2, padding=\"causal\", dilation_rate=1, kernel_initializer='he_normal')(cnn)\n",
    "cnn = LeakyReLU(0.3)(cnn)\n",
    "cnn = Conv1D(filters=32, kernel_size=5, strides=2, padding=\"causal\", dilation_rate=1, kernel_initializer='he_normal')(cnn)\n",
    "cnn = LeakyReLU(0.3)(cnn)\n",
    "cnn = Conv1D(filters=32, kernel_size=3, strides=2, padding=\"causal\", dilation_rate=1, kernel_initializer='he_normal')(cnn)\n",
    "cnn = LeakyReLU(0.3)(cnn)\n",
    "cnn = Dropout(rate=0.1)(cnn)\n",
    "for i in range(NMODULES):\n",
    "    cnn = DilatedDropoutSkipModule(cnn, DROP_RATES[i])\n",
    "cnn = Flatten()(cnn)\n",
    "cnn = Dense(batch_y_shape[1], kernel_initializer='he_normal', activation=final_activation)(cnn)\n",
    "model = Model(inputs=data, outputs=cnn)\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.output_shape)\n",
    "\n",
    "# The label specific metric, dependant on the problem type from custom settings.\n",
    "label_metric = {ONE_HOT: categorical_accuracy, MULTI_LABEL: \"accuracy\"}[problem_type]\n",
    "    \n",
    "# Compile with custom settings defined earlier\n",
    "model.compile(optimizer=optimizer, loss=LOSSES[loss], metrics=[label_metric, RAON_accuracy, LOSSES[loss + 1 % 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1587/1587 [==============================] - 1417s 893ms/step - loss: 0.0697 - categorical_accuracy: 0.0238 - rounded_all_or_nothing_acc: 5.6711e-04 - kullback_leibler_divergence: 5.0328 - val_loss: 0.0604 - val_categorical_accuracy: 0.0500 - val_rounded_all_or_nothing_acc: 1.1364e-04 - val_kullback_leibler_divergence: 4.2630\n",
      "Epoch 2/10\n",
      "1587/1587 [==============================] - 1337s 843ms/step - loss: 0.0616 - categorical_accuracy: 0.0438 - rounded_all_or_nothing_acc: 3.2766e-04 - kullback_leibler_divergence: 4.3627 - val_loss: 0.0593 - val_categorical_accuracy: 0.0629 - val_rounded_all_or_nothing_acc: 3.7879e-05 - val_kullback_leibler_divergence: 4.1706\n",
      "Epoch 3/10\n",
      "1587/1587 [==============================] - 1363s 859ms/step - loss: 0.0603 - categorical_accuracy: 0.0520 - rounded_all_or_nothing_acc: 4.2848e-04 - kullback_leibler_divergence: 4.2525 - val_loss: 0.0586 - val_categorical_accuracy: 0.0715 - val_rounded_all_or_nothing_acc: 3.7879e-05 - val_kullback_leibler_divergence: 4.1111\n",
      "Epoch 4/10\n",
      "1587/1587 [==============================] - 1703s 1s/step - loss: 0.0594 - categorical_accuracy: 0.0585 - rounded_all_or_nothing_acc: 4.1588e-04 - kullback_leibler_divergence: 4.1772 - val_loss: 0.0579 - val_categorical_accuracy: 0.0809 - val_rounded_all_or_nothing_acc: 7.5758e-05 - val_kullback_leibler_divergence: 4.0501\n",
      "Epoch 5/10\n",
      "1587/1587 [==============================] - 1307s 824ms/step - loss: 0.0587 - categorical_accuracy: 0.0677 - rounded_all_or_nothing_acc: 6.8053e-04 - kullback_leibler_divergence: 4.1138 - val_loss: 0.0571 - val_categorical_accuracy: 0.0916 - val_rounded_all_or_nothing_acc: 1.5152e-04 - val_kullback_leibler_divergence: 3.9860\n",
      "Epoch 6/10\n",
      "1587/1587 [==============================] - 1449s 913ms/step - loss: 0.0579 - categorical_accuracy: 0.0746 - rounded_all_or_nothing_acc: 9.4518e-04 - kullback_leibler_divergence: 4.0497 - val_loss: 0.0564 - val_categorical_accuracy: 0.1008 - val_rounded_all_or_nothing_acc: 1.5152e-04 - val_kullback_leibler_divergence: 3.9211\n",
      "Epoch 7/10\n",
      "1587/1587 [==============================] - 1158s 730ms/step - loss: 0.0572 - categorical_accuracy: 0.0821 - rounded_all_or_nothing_acc: 0.0011 - kullback_leibler_divergence: 3.9882 - val_loss: 0.0556 - val_categorical_accuracy: 0.1084 - val_rounded_all_or_nothing_acc: 2.2727e-04 - val_kullback_leibler_divergence: 3.8574\n",
      "Epoch 8/10\n",
      "1587/1587 [==============================] - 1132s 713ms/step - loss: 0.0564 - categorical_accuracy: 0.0926 - rounded_all_or_nothing_acc: 0.0012 - kullback_leibler_divergence: 3.9232 - val_loss: 0.0548 - val_categorical_accuracy: 0.1148 - val_rounded_all_or_nothing_acc: 3.7879e-04 - val_kullback_leibler_divergence: 3.7903\n",
      "Epoch 9/10\n",
      "1587/1587 [==============================] - 1137s 717ms/step - loss: 0.0557 - categorical_accuracy: 0.0985 - rounded_all_or_nothing_acc: 0.0017 - kullback_leibler_divergence: 3.8632 - val_loss: 0.0540 - val_categorical_accuracy: 0.1251 - val_rounded_all_or_nothing_acc: 4.1667e-04 - val_kullback_leibler_divergence: 3.7251\n",
      "Epoch 10/10\n",
      "1587/1587 [==============================] - 1133s 714ms/step - loss: 0.0551 - categorical_accuracy: 0.1057 - rounded_all_or_nothing_acc: 0.0021 - kullback_leibler_divergence: 3.8092 - val_loss: 0.0534 - val_categorical_accuracy: 0.1314 - val_rounded_all_or_nothing_acc: 4.5455e-04 - val_kullback_leibler_divergence: 3.6735\n"
     ]
    }
   ],
   "source": [
    "# Training logs\n",
    "log_dir = \"logs/{}\".format(model_name)\n",
    "# Tensorboard log\n",
    "tb_log = TensorBoard(log_dir=log_dir)\n",
    "# Custom time log\n",
    "time_log = Time_Callback(log_dir=log_dir)\n",
    "\n",
    "# Train model\n",
    "epochs = 10\n",
    "dataset_perc = 1\n",
    "training_history = model.fit_generator(\n",
    "                generator = generators[\"training\"],\n",
    "                steps_per_epoch = int(N[\"training\"]*dataset_perc) // batch_size,\n",
    "                validation_data = generators[\"validation\"],\n",
    "                validation_steps = int(N[\"validation\"]*dataset_perc) // batch_size,\n",
    "                epochs = epochs,\n",
    "                callbacks = [tb_log, time_log],\n",
    "                use_multiprocessing = use_multiprocessing,\n",
    "                workers = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of model\n",
    "\n",
    "After 10 epochs of training and validation with the training and validation data sets, a seperate evaluation run calculated the final accuracy of the model using the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05341424102626854,\n",
       " 0.1297348454580501,\n",
       " 0.0006060605854586219,\n",
       " 3.6725936116594258]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "model.evaluate_generator(\n",
    "    generators[\"test\"],\n",
    "    int(N[\"test\"]*dataset_perc) // batch_size,\n",
    "    use_multiprocessing = use_multiprocessing,\n",
    "    workers = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights to `/models` directory\n",
    "save_dir = os.path.join(os.getcwd(), \"models\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_dir, \"{}.json\".format(model_name)), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(os.path.join(save_dir, \"{}.h5\".format(model_name)))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples of predictions using test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators[\"test\"].on_epoch_end()\n",
    "batch0_test = generators[\"test\"].__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['beater', 'stick'], 'kit_label': ['bass_drum', 'low_tom'], 'tech_label': ['normal', 'normal']}\n",
      "Prediction:\n",
      "\t[0.093, 0.0, 0.001, 0.0, 0.003, 0.008, 0.005, 0.0, 0.0, 0.003, 0.014, 0.02, 0.018, 0.045, 0.022, 0.03, 0.018, 0.016, 0.02, 0.0, 0.001, 0.001, 0.002, 0.002, 0.0, 0.0, 0.001, 0.003, 0.005, 0.003, 0.001, 0.001, 0.004, 0.002, 0.003, 0.002, 0.001, 0.0, 0.002, 0.003, 0.006, 0.001, 0.002, 0.005, 0.004, 0.003, 0.004, 0.008, 0.002, 0.002, 0.003, 0.002, 0.002, 0.012, 0.01, 0.018, 0.02, 0.014, 0.011, 0.019, 0.022, 0.028, 0.016, 0.017, 0.026, 0.024, 0.022, 0.015, 0.018, 0.021, 0.007, 0.015, 0.019, 0.023, 0.019, 0.011, 0.019, 0.019, 0.01, 0.015, 0.024, 0.013, 0.018, 0.025, 0.019, 0.014, 0.02],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 1\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['stick'], 'kit_label': ['low_tom'], 'tech_label': ['normal']}\n",
      "Prediction:\n",
      "\t[0.031, 0.023, 0.013, 0.018, 0.081, 0.068, 0.069, 0.012, 0.017, 0.02, 0.012, 0.01, 0.009, 0.016, 0.005, 0.008, 0.009, 0.006, 0.01, 0.011, 0.007, 0.017, 0.013, 0.007, 0.011, 0.007, 0.01, 0.01, 0.012, 0.013, 0.008, 0.014, 0.011, 0.008, 0.009, 0.012, 0.012, 0.006, 0.008, 0.011, 0.007, 0.017, 0.012, 0.011, 0.006, 0.01, 0.01, 0.006, 0.01, 0.02, 0.018, 0.01, 0.007, 0.006, 0.01, 0.007, 0.003, 0.003, 0.008, 0.008, 0.008, 0.003, 0.005, 0.008, 0.006, 0.005, 0.009, 0.003, 0.005, 0.005, 0.007, 0.007, 0.005, 0.007, 0.004, 0.005, 0.006, 0.011, 0.003, 0.005, 0.007, 0.007, 0.004, 0.004, 0.004, 0.006, 0.007],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 2\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['stick', 'stick'], 'kit_label': ['crash', 'hi_hat'], 'tech_label': ['normal', 'open']}\n",
      "Prediction:\n",
      "\t[0.003, 0.116, 0.01, 0.123, 0.011, 0.016, 0.007, 0.027, 0.022, 0.008, 0.006, 0.006, 0.003, 0.001, 0.003, 0.005, 0.003, 0.008, 0.002, 0.015, 0.04, 0.044, 0.021, 0.007, 0.027, 0.013, 0.016, 0.004, 0.02, 0.004, 0.019, 0.008, 0.004, 0.023, 0.029, 0.012, 0.027, 0.035, 0.018, 0.004, 0.007, 0.014, 0.008, 0.006, 0.004, 0.004, 0.006, 0.009, 0.011, 0.015, 0.006, 0.005, 0.006, 0.007, 0.008, 0.005, 0.006, 0.003, 0.01, 0.015, 0.003, 0.002, 0.001, 0.002, 0.004, 0.002, 0.002, 0.003, 0.005, 0.002, 0.005, 0.008, 0.006, 0.002, 0.002, 0.003, 0.001, 0.002, 0.002, 0.002, 0.004, 0.001, 0.003, 0.003, 0.001, 0.003, 0.003],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 3\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['beater', 'stick', 'stick'], 'kit_label': ['bass_drum', 'hi_hat', 'low_tom'], 'tech_label': ['normal', 'open', 'normal']}\n",
      "Prediction:\n",
      "\t[0.003, 0.0, 0.0, 0.0, 0.001, 0.002, 0.004, 0.0, 0.0, 0.0, 0.005, 0.007, 0.027, 0.009, 0.018, 0.027, 0.008, 0.004, 0.023, 0.001, 0.0, 0.001, 0.004, 0.01, 0.0, 0.0, 0.001, 0.001, 0.004, 0.007, 0.0, 0.0, 0.0, 0.0, 0.002, 0.012, 0.001, 0.0, 0.003, 0.005, 0.011, 0.0, 0.001, 0.002, 0.007, 0.002, 0.002, 0.012, 0.007, 0.006, 0.009, 0.001, 0.0, 0.007, 0.02, 0.023, 0.025, 0.026, 0.007, 0.03, 0.017, 0.013, 0.011, 0.015, 0.008, 0.006, 0.006, 0.021, 0.02, 0.022, 0.024, 0.02, 0.006, 0.023, 0.058, 0.006, 0.014, 0.021, 0.061, 0.024, 0.013, 0.05, 0.036, 0.037, 0.047, 0.016, 0.015],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 4\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['stick'], 'kit_label': ['ride'], 'tech_label': ['bell']}\n",
      "Prediction:\n",
      "\t[0.023, 0.032, 0.032, 0.058, 0.036, 0.026, 0.011, 0.04, 0.084, 0.06, 0.007, 0.011, 0.01, 0.004, 0.003, 0.002, 0.007, 0.006, 0.008, 0.026, 0.023, 0.011, 0.006, 0.003, 0.022, 0.02, 0.013, 0.013, 0.01, 0.008, 0.016, 0.012, 0.016, 0.015, 0.009, 0.003, 0.025, 0.013, 0.008, 0.003, 0.004, 0.011, 0.015, 0.012, 0.003, 0.011, 0.008, 0.006, 0.006, 0.004, 0.003, 0.019, 0.017, 0.005, 0.006, 0.005, 0.002, 0.003, 0.006, 0.007, 0.004, 0.005, 0.003, 0.003, 0.01, 0.01, 0.003, 0.005, 0.003, 0.003, 0.005, 0.005, 0.009, 0.003, 0.002, 0.004, 0.007, 0.003, 0.001, 0.004, 0.003, 0.003, 0.002, 0.002, 0.001, 0.003, 0.005],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 5\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['stick'], 'kit_label': ['high_tom'], 'tech_label': ['normal']}\n",
      "Prediction:\n",
      "\t[0.02, 0.001, 0.003, 0.002, 0.015, 0.011, 0.014, 0.002, 0.001, 0.02, 0.018, 0.013, 0.017, 0.024, 0.014, 0.02, 0.026, 0.011, 0.016, 0.005, 0.004, 0.006, 0.007, 0.005, 0.003, 0.002, 0.007, 0.008, 0.008, 0.008, 0.004, 0.004, 0.007, 0.004, 0.008, 0.009, 0.006, 0.003, 0.008, 0.008, 0.007, 0.009, 0.006, 0.013, 0.005, 0.01, 0.007, 0.015, 0.006, 0.004, 0.008, 0.011, 0.008, 0.018, 0.013, 0.013, 0.016, 0.014, 0.009, 0.018, 0.018, 0.016, 0.014, 0.015, 0.014, 0.015, 0.012, 0.016, 0.012, 0.013, 0.01, 0.011, 0.015, 0.018, 0.021, 0.015, 0.015, 0.02, 0.014, 0.013, 0.017, 0.011, 0.02, 0.019, 0.024, 0.017, 0.015],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 6\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['stick', 'stick'], 'kit_label': ['low_tom', 'ride'], 'tech_label': ['normal', 'bell']}\n",
      "Prediction:\n",
      "\t[0.002, 0.015, 0.004, 0.023, 0.01, 0.016, 0.037, 0.012, 0.003, 0.005, 0.006, 0.016, 0.006, 0.005, 0.019, 0.007, 0.011, 0.009, 0.017, 0.007, 0.022, 0.01, 0.018, 0.014, 0.009, 0.01, 0.024, 0.013, 0.021, 0.023, 0.005, 0.006, 0.004, 0.005, 0.016, 0.011, 0.012, 0.008, 0.016, 0.009, 0.013, 0.009, 0.004, 0.007, 0.031, 0.015, 0.017, 0.015, 0.024, 0.017, 0.022, 0.008, 0.004, 0.012, 0.01, 0.006, 0.012, 0.006, 0.007, 0.009, 0.006, 0.005, 0.003, 0.004, 0.008, 0.008, 0.014, 0.007, 0.018, 0.011, 0.008, 0.026, 0.01, 0.009, 0.013, 0.006, 0.01, 0.005, 0.007, 0.01, 0.011, 0.008, 0.014, 0.013, 0.013, 0.012, 0.008],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 7\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['beater', 'stick', 'stick'], 'kit_label': ['bass_drum', 'hi_hat', 'ride'], 'tech_label': ['normal', 'normal', 'bell']}\n",
      "Prediction:\n",
      "\t[0.009, 0.0, 0.0, 0.0, 0.002, 0.004, 0.006, 0.0, 0.0, 0.0, 0.011, 0.027, 0.024, 0.043, 0.013, 0.007, 0.016, 0.017, 0.01, 0.0, 0.0, 0.002, 0.002, 0.006, 0.0, 0.0, 0.001, 0.002, 0.004, 0.016, 0.001, 0.001, 0.0, 0.002, 0.002, 0.003, 0.001, 0.0, 0.002, 0.001, 0.005, 0.001, 0.001, 0.001, 0.01, 0.002, 0.004, 0.005, 0.011, 0.004, 0.001, 0.001, 0.001, 0.049, 0.01, 0.02, 0.014, 0.019, 0.01, 0.037, 0.018, 0.007, 0.009, 0.006, 0.07, 0.011, 0.031, 0.014, 0.022, 0.004, 0.034, 0.128, 0.013, 0.017, 0.02, 0.003, 0.004, 0.016, 0.015, 0.019, 0.009, 0.022, 0.009, 0.007, 0.007, 0.032, 0.012],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 8\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['beater', 'stick', 'stick'], 'kit_label': ['bass_drum', 'hi_hat', 'low_tom'], 'tech_label': ['normal', 'normal', 'normal']}\n",
      "Prediction:\n",
      "\t[0.007, 0.001, 0.001, 0.001, 0.009, 0.011, 0.006, 0.002, 0.001, 0.005, 0.005, 0.011, 0.01, 0.022, 0.042, 0.016, 0.008, 0.015, 0.012, 0.001, 0.002, 0.003, 0.009, 0.009, 0.002, 0.002, 0.004, 0.002, 0.012, 0.005, 0.003, 0.002, 0.004, 0.002, 0.004, 0.014, 0.004, 0.005, 0.009, 0.005, 0.011, 0.003, 0.005, 0.013, 0.006, 0.009, 0.005, 0.009, 0.008, 0.007, 0.007, 0.007, 0.006, 0.017, 0.012, 0.006, 0.017, 0.024, 0.014, 0.008, 0.012, 0.024, 0.024, 0.022, 0.014, 0.049, 0.009, 0.014, 0.016, 0.012, 0.013, 0.01, 0.013, 0.019, 0.01, 0.02, 0.025, 0.012, 0.026, 0.026, 0.026, 0.018, 0.02, 0.022, 0.03, 0.019, 0.013],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n",
      "Sample 9\n",
      "Actual:\n",
      "\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],\n",
      "\t{'hit_label': ['stick', 'stick'], 'kit_label': ['hi_hat', 'snare'], 'tech_label': ['normal', 'normal']}\n",
      "Prediction:\n",
      "\t[0.08, 0.039, 0.054, 0.028, 0.084, 0.073, 0.053, 0.028, 0.033, 0.048, 0.007, 0.007, 0.007, 0.006, 0.003, 0.003, 0.007, 0.006, 0.007, 0.015, 0.008, 0.011, 0.007, 0.007, 0.013, 0.008, 0.011, 0.015, 0.012, 0.007, 0.013, 0.015, 0.011, 0.009, 0.008, 0.006, 0.01, 0.012, 0.01, 0.01, 0.004, 0.012, 0.012, 0.012, 0.003, 0.009, 0.008, 0.007, 0.005, 0.009, 0.005, 0.01, 0.014, 0.005, 0.006, 0.003, 0.002, 0.002, 0.004, 0.004, 0.004, 0.002, 0.002, 0.001, 0.004, 0.004, 0.005, 0.002, 0.002, 0.001, 0.004, 0.005, 0.003, 0.002, 0.001, 0.003, 0.004, 0.002, 0.001, 0.002, 0.003, 0.002, 0.001, 0.002, 0.001, 0.005, 0.004],\n",
      "\t{'hit_label': [], 'kit_label': [], 'tech_label': []}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical_accuracy (avg) 0.0\n",
      "RAON accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "preds, trues = [], []\n",
    "for i in range(10):\n",
    "    x, y = batch0_test[0][i], batch0_test[1][i]\n",
    "    pred_y = np.reshape(model.predict(x.reshape(1, batch_x_shape[1], batch_x_shape[2])), batch_y_shape[1])\n",
    "    print(\"Sample\", i)\n",
    "    print(\"Actual:\\n\\t{},\\n\\t{}\\nPrediction:\\n\\t{},\\n\\t{}\\n\".format(y, onehot_superclass_ys_to_labels(y), [round(p_y, 3) for p_y in pred_y.tolist()], onehot_superclass_ys_to_labels([int(round(p_y)) for p_y in pred_y.tolist()])))\n",
    "    preds.append(pred_y)\n",
    "    trues.append(y)\n",
    "\n",
    "preds_tensor = K.variable(np.array(preds))\n",
    "trues_tensor = K.variable(np.array(trues))\n",
    "print(\"Categorical_accuracy (avg)\", K.eval(K.mean(categorical_accuracy(trues_tensor, preds_tensor))))\n",
    "print(\"RAON accuracy: \", K.eval(RAON_accuracy(trues_tensor, preds_tensor)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
