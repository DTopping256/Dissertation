{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read settings file...\n",
      "\tRead successfully!\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "import sys\n",
    "import tensorflow.keras.backend as K\n",
    "import keras.preprocessing.sequence\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.layers import concatenate, Dense, Dropout, Layer, Conv1D, Activation, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Sequential\n",
    "from scipy import signal\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Allows me to import my modules\n",
    "sys.path.append('./modules')\n",
    "from audio_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kltls = ['bass_drum-normal','hi_hat-normal',\n",
    "  'hi_hat-open',\n",
    "  'high_tom-normal',\n",
    "  'ride-normal',\n",
    "  'ride-bell',\n",
    "  'crash-normal',\n",
    "  'snare-normal',\n",
    "  'low_tom-normal',\n",
    "  'mid_tom-normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_ys(labels):\n",
    "    ys = np.zeros(len(kltls))\n",
    "    for n in range(len(kltls)):\n",
    "        kl, tl = kltls[n].split(\"-\")\n",
    "        for label_i in range(len(labels[\"hit_label\"])):\n",
    "            if (kl in labels[\"kit_label\"][label_i] and tl in labels[\"tech_label\"][label_i]):\n",
    "                ys[n] = 1\n",
    "    return ys\n",
    "\n",
    "def ys_to_labels(ys, threshold = 0.6):\n",
    "    labels = {\"hit_label\": [], \"kit_label\": [], \"tech_label\": []}\n",
    "    for n in range(len(kltls)):\n",
    "        kl, tl = kltls[n].split(\"-\")\n",
    "        if (ys[n] > threshold):\n",
    "            hl = \"beater\" if kl == \"bass_drum\" else \"stick\"\n",
    "            labels[\"hit_label\"].append(hl)\n",
    "            labels[\"kit_label\"].append(kl)\n",
    "            labels[\"tech_label\"].append(tl)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioGenerator(Sequence):\n",
    "    def get_ys(self, labels):\n",
    "        return labels_to_ys(labels)\n",
    "    \n",
    "    def __init__(self, filenames, labels, data_type):\n",
    "        self.filenames, self.labels, self.batch_size = filenames, labels, SETTINGS.data[data_type][\"batch_size\"]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([np.loadtxt(file_name) for file_name in batch_x]), np.array(list(map(self.get_ys, batch_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "generators = {\"training\": None, \"test\": None}\n",
    "for data_type in generators.keys():\n",
    "    sample_metadata = get_file_classes(data_type)\n",
    "    filenames = [sm[\"filepath\"] for sm in sample_metadata]\n",
    "    labels = [sm[\"labels\"] for sm in sample_metadata]\n",
    "    generators[data_type] = AudioGenerator(filenames, labels, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picklable: True\n"
     ]
    }
   ],
   "source": [
    "# Test whether generator arguments are picklable (whether they can be multiprocessed)\n",
    "use_multiprocessing = True\n",
    "for gen in generators:\n",
    "    try:\n",
    "        pickle.dumps(gen)\n",
    "    except:\n",
    "        print(sys.exc_info())\n",
    "        use_multiprocessing = False\n",
    "        break\n",
    "print(\"Picklable:\", use_multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://keras.io/layers/writing-your-own-keras-layers/\n",
    "class InceptionModule(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(InceptionModule, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.conv_1_kernel = self.add_weight(name='kernel1', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.conv_3a_kernel = self.add_weight(name='kernel3a', \n",
    "                                      shape=(input_shape[2], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.conv_3b_kernel = self.add_weight(name='kernel3b', \n",
    "                                      shape=(input_shape[3], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.conv_5a_kernel = self.add_weight(name='kernel5a', \n",
    "                                      shape=(input_shape[4], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.conv_5b_kernel = self.add_weight(name='kernel5b', \n",
    "                                      shape=(input_shape[5], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.conv_7a_kernel = self.add_weight(name='kernel7a', \n",
    "                                      shape=(input_shape[6], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.conv_7b_kernel = self.add_weight(name='kernel7b', \n",
    "                                      shape=(input_shape[7], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(InceptionModule, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        # Skip connection (uses input in concat)\n",
    "        skip = x\n",
    "        # Size 1 kernal conv of input (with tanh activation)\n",
    "        conv_1_tower = K.conv1d(x, self.conv_1_kernal)\n",
    "        conv_1_tower = K.tanh(conv_1_tower)\n",
    "        # Size 1 -> size 3 kernal conv of input (with tanh activation)\n",
    "        conv_3_tower = K.conv1D(x, self.conv_3a_kernal, padding=\"same\")\n",
    "        conv_3_tower = K.conv1D(conv_3_tower, self.conv_3b_kernal, padding=\"causal\")\n",
    "        conv_3_tower = K.tanh(conv_3_tower)\n",
    "        # Size 1 -> size 5 kernal conv of input (with tanh activation)\n",
    "        conv_5_tower = K.conv1D(x, self.conv_5a_kernal, padding=\"same\")\n",
    "        conv_5_tower = K.conv1D(conv_5_tower, self.conv_5b_kernal, padding=\"causal\")\n",
    "        conv_5_tower = K.tanh(conv_5_tower)\n",
    "        # Size 1 -> size 7 kernal conv of input (with tanh activation)\n",
    "        conv_7_tower = K.conv1D(x, self.conv_7a_kernal, padding=\"same\")\n",
    "        conv_7_tower = K.conv1D(conv_7_tower, self.conv_7b_kernal, padding=\"causal\")\n",
    "        conv_7_tower = K.tanh(conv_7_tower)\n",
    "        # Concatenate all activation images\n",
    "        return K.concatenate([skip, conv_1_tower, conv_3_tower, conv_5_tower, conv_7_tower], axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# Reusable dausal convolution layer structure\n",
    "def CausalConvActLayer(nn, kernal_size, strides, filters):\n",
    "    nn.add(Conv1D(filters=filters, kernal_size=kernal_size, strides=strides, padding=\"causal\"))\n",
    "    nn.add(Activation(\"tanh\"))\n",
    "    \n",
    "# Reusable dilated convolution / inception module / dropout layer\n",
    "def DilatedInceptionModuleLayer(nn, drop_rate):\n",
    "    nn.add(Conv1D(kernal_size=3, padding=\"causal\", dilation_rate=2))\n",
    "    nn.add(Activation(\"tanh\"))\n",
    "    nn.add(InceptionModule())\n",
    "    nn.add(Activation(\"tanh\"))\n",
    "    nn.add(Dropout(drop_rate))\n",
    "\n",
    "cca_layers = [\n",
    "    {\"kernal_size\": 7,\n",
    "    \"strides\": 3,\n",
    "    \"filters\": 50},\n",
    "    {\"kernal_size\": 7,\n",
    "    \"strides\": 2,\n",
    "    \"filters\": 25},\n",
    "    {\"kernal_size\": 5,\n",
    "    \"strides\": 2,\n",
    "    \"filters\": 10}\n",
    "]\n",
    "dim_layers = [\n",
    "    {\n",
    "        \"drop_rate\": 0.1\n",
    "    },\n",
    "    {\n",
    "        \"drop_rate\": 0.15\n",
    "    },\n",
    "    {\n",
    "        \"drop_rate\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"drop_rate\": 0.25\n",
    "    },\n",
    "    {\n",
    "        \"drop_rate\": 0.3\n",
    "    }\n",
    "]\n",
    "\n",
    "# MODEL\n",
    "\"\"\"\n",
    "Rationale: \n",
    "\n",
    "3 \"CausalConvAct\" convolution layers which reduce the size of the sample space while increasing the size of the convolution space.\n",
    "- Providing downscaling\n",
    "(Feature extraction, while preserving temporal relationships)\n",
    "\n",
    "Then \"DilatedInceptionModule\" layers which retain the size of the sample space while increasing the depth of the \n",
    "\"\"\"\n",
    "for cca_layer in cca_layers:\n",
    "    CausalConvActLayer(model, *cca_layer)\n",
    "model.add(Dropout(0.05))\n",
    "for dim_layer in dim_layers:\n",
    "    DilatedInceptionModuleLayer(model, *dim_layer)\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit_generator(generator=generators[\"training\"],\n",
    "                   validation_data=generators[\"validation\"],\n",
    "                   use_multiprocessing=use_multiprocessing,\n",
    "                   workers=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
